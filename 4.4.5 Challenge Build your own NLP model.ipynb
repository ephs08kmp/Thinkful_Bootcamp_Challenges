{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.5 Challenge: Build your own NLP model\n",
    "__Instructions__\n",
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# NLP \n",
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Processing - PLOS Abstracts\n",
    "The corpus I decided to use for this challenge is from PLOS searches.  PLOS is a non-profit publisher of scientific articles. I pulled abstract searches from the PLOS API with the following title searches: cancer, HIV, and heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response1 = requests.get(r'http://api.plos.org/search?q=title:\"cancer\"&fl=abstract&wt=json&api_key=51bQhx63o6--UjRBhkHb')\n",
    "response2 = requests.get(r'http://api.plos.org/search?q=title:\"HIV\"&fl=abstract&wt=json&api_key=51bQhx63o6--UjRBhkHb')\n",
    "response3 = requests.get(r'http://api.plos.org/search?q=title:\"heart disease\"&fl=abstract&wt=json&api_key=51bQhx63o6--UjRBhkHb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Pulling JSON data into usable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_raw = response1.json()\n",
    "hiv_raw = response2.json()\n",
    "heart_raw = response3.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling out just the abstracts of each article into one string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\nSocietal perceptions may factor into the high rates of nontreatment in patients with lung cancer. To determine whether bias exists toward lung cancer, a study using the Implicit Association Test me\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = ''\n",
    "for article in cancer_raw['response']['docs']:\n",
    "    art = re.sub(r'[\\[\\]]','', str(article['abstract']))\n",
    "    cancer = cancer + art\n",
    "\n",
    "cancer[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Background: Whether spontaneous low levels of HIV-1 RNA in blood plasma correlate with low levels of HIV-1 RNA in seminal plasma has never been investigated in HIV controller (HIC) men so far. Method\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiv = ''\n",
    "for article in hiv_raw['response']['docs']:\n",
    "    art = re.sub(r'[\\[\\]]','', str(article['abstract']))\n",
    "    hiv = hiv + art\n",
    "\n",
    "hiv[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\nThere are 16.5 million newborns in China annually. However, the incidence of congenital heart disease (CHD) has not been evaluated. In 2004, we launched an active province-wide hospital-based CHD r\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart = ''\n",
    "for article in heart_raw['response']['docs']:\n",
    "    art = re.sub(r'[\\[\\]]','', str(article['abstract']))\n",
    "    heart = heart + art\n",
    "\n",
    "heart[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning\n",
    "Removing --, which is not processed by our NLP models; removing excess quotation marks, and removing all digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', ' ', text)\n",
    "    text = re.sub(r'[\\']', '', text)\n",
    "    text = re.sub(r'[\\\\]', '', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cancer_clean = text_cleaner(cancer)\n",
    "hiv_clean = text_cleaner(hiv)\n",
    "heart_clean = text_cleaner(heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nThere are . million newborns in China annually. However, the incidence of congenital heart disease (CHD) has not been evaluated. In , we launched an active province-wide hospital-based CHD registry i'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_clean[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Parsing with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "cancer_doc = nlp(cancer_clean)\n",
    "hiv_doc = nlp(hiv_clean)\n",
    "heart_doc = nlp(heart_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting each topic into individual sentences for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    }
   ],
   "source": [
    "cancer_sents = [[sent, 'Cancer'] for sent in cancer_doc.sents]\n",
    "hiv_sents = [[sent, 'HIV'] for sent in hiv_doc.sents]\n",
    "heart_sents = [[sent, 'Heart'] for sent in heart_doc.sents]\n",
    "\n",
    "sentences = pd.DataFrame(cancer_sents + hiv_sents + heart_sents)\n",
    "sentences.head()\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating BOW Features\n",
    "Defining functions to identify most common words and the create features from those words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    allwords = [token.lemma_\n",
    "               for token in text\n",
    "               if not token.is_punct\n",
    "               and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:,common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_ \n",
    "                for token in sentence\n",
    "                if (\n",
    "                    not token.is_punct\n",
    "                    and not token.is_stop\n",
    "                    and token.lemma_ in common_words\n",
    "                )]\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        if i%100 == 0:\n",
    "            print('Processing row {}'.format(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding common words from three searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerwords = bag_of_words(cancer_doc)\n",
    "hivwords = bag_of_words(hiv_doc)\n",
    "heartwords = bag_of_words(heart_doc)\n",
    "\n",
    "common_words = set(cancerwords + hivwords + heartwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating features from all searches from common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 100\n",
      "Processing row 200\n",
      "Processing row 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>substantially</th>\n",
       "      <th>transmission</th>\n",
       "      <th>therapeutics.nauthor</th>\n",
       "      <th>incorporate</th>\n",
       "      <th>disease</th>\n",
       "      <th>cardioprotectors/</th>\n",
       "      <th>estimate</th>\n",
       "      <th>sperm</th>\n",
       "      <th>arr</th>\n",
       "      <th>multiple</th>\n",
       "      <th>...</th>\n",
       "      <th>comparable</th>\n",
       "      <th>concomitant</th>\n",
       "      <th>underlie</th>\n",
       "      <th>comparison</th>\n",
       "      <th>subtype</th>\n",
       "      <th>like</th>\n",
       "      <th>child</th>\n",
       "      <th>soluble</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(nSocietal, perceptions, may, factor, into, th...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(To, determine, whether, bias, exists, toward,...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Participants, were, primarily, recruited, fro...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Explicit, attitudes, regarding, lung, and, br...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Participants’, responses, to, descriptive, an...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  substantially transmission therapeutics.nauthor incorporate disease  \\\n",
       "0             0            0                    0           0       0   \n",
       "1             0            0                    0           0       0   \n",
       "2             0            0                    0           0       0   \n",
       "3             0            0                    0           0       0   \n",
       "4             0            0                    0           0       0   \n",
       "\n",
       "  cardioprotectors/ estimate sperm arr multiple     ...     comparable  \\\n",
       "0                 0        0     0   0        0     ...              0   \n",
       "1                 0        0     0   0        0     ...              0   \n",
       "2                 0        0     0   0        0     ...              0   \n",
       "3                 0        0     0   0        0     ...              0   \n",
       "4                 0        0     0   0        0     ...              0   \n",
       "\n",
       "  concomitant underlie comparison subtype like child soluble  \\\n",
       "0           0        0          0       0    0     0       0   \n",
       "1           0        0          0       0    0     0       0   \n",
       "2           0        0          0       0    0     0       0   \n",
       "3           0        0          0       0    0     0       0   \n",
       "4           0        0          0       0    0     0       0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (nSocietal, perceptions, may, factor, into, th...      Cancer  \n",
       "1  (To, determine, whether, bias, exists, toward,...      Cancer  \n",
       "2  (Participants, were, primarily, recruited, fro...      Cancer  \n",
       "3  (Explicit, attitudes, regarding, lung, and, br...      Cancer  \n",
       "4  (Participants’, responses, to, descriptive, an...      Cancer  \n",
       "\n",
       "[5 rows x 1501 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tf-idf features\n",
    "Second NLP model - converting sentencs into numeric vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2148e86cfcc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#Applying the vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msent_tfidf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcancer_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of features: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msent_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             raise ValueError(\n\u001b[0;32m--> 860\u001b[0;31m                 \u001b[0;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m                 \"string object received.\")\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(encoding='ASCII',\n",
    "                             max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "#Applying the vectorizer\n",
    "sent_tfidf=vectorizer.fit_transform(cancer_clean)\n",
    "print(\"Number of features: %d\" % sent_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(sent_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[5])\n",
    "print('Tf_idf vector:', tfidf_bypara[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code keeps throwing errors.  If I use the clean version of the text, it says that it needs a raw text document.  If I use the sentences, it says that tokens don't have attribute lower.  I've tried to make this work, without success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Models to Predict Outcomes\n",
    "I will use the BOW features to predict outcomes using Radom Forest Classifier, Logistic Regression, and Gradient Boosting Classifier to see which best predicts the topic of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9684684684684685\n",
      "\n",
      "Test set score: 0.7432432432432432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222, 1499) (222,)\n",
      "Training set score: 0.963963963963964\n",
      "\n",
      "Test set score: 0.8243243243243243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9504504504504504\n",
      "\n",
      "Test set score: 0.7972972972972973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three models had approximately the same accuracy scores for the training set.  The logistic regression model had the highest score for the test set.  I will use this model to optimize the predictions.\n",
    "\n",
    "#### Optimizing Logistic Regression Model\n",
    "Using the Logisitic Regression default model, which had the highest accuracy on the test set, I will attempt to increase the accuracy of the model.\n",
    "\n",
    "First, I noticed that there were only around 1500 common words (eventhough the function specifies that there can be 2000 common words.  I will try reducing the number of common words used by the function to reduce the overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words2(text):\n",
    "    allwords = [token.lemma_\n",
    "               for token in text\n",
    "               if not token.is_punct\n",
    "               and not token.is_stop]\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response1b = requests.get(r'http://api.plos.org/search?q=title:\"cancer\"&fl=abstract&wt=json&api_key=51bQhx63o6--UjRBhkHb&start=10&rows=20')\n",
    "response2b = requests.get(r'http://api.plos.org/search?q=title:\"HIV\"&fl=abstract&wt=json&api_key=51bQhx63o6--UjRBhkHb&start=10&rows=20')\n",
    "response3b = requests.get(r'http://api.plos.org/search?q=title:\"heart disease\"&fl=abstract&wt=json&api_key=51bQhx63o6--UjRBhkHb&start=10&rows=20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Pulling JSON data into usable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_raw2 = response1b.json()\n",
    "hiv_raw2 = response2b.json()\n",
    "heart_raw2 = response3b.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling out just the abstracts of each article into one string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\nSocietal perceptions may factor into the high rates of nontreatment in patients with lung cancer. To determine whether bias exists toward lung cancer, a study using the Implicit Association Test me\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for article in cancer_raw2['response']['docs']:\n",
    "    art = re.sub(r'[\\[\\]]','', str(article['abstract']))\n",
    "    cancer = cancer + art\n",
    "\n",
    "cancer[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Background: Whether spontaneous low levels of HIV-1 RNA in blood plasma correlate with low levels of HIV-1 RNA in seminal plasma has never been investigated in HIV controller (HIC) men so far. Method\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for article in hiv_raw2['response']['docs']:\n",
    "    art = re.sub(r'[\\[\\]]','', str(article['abstract']))\n",
    "    hiv = hiv + art\n",
    "\n",
    "hiv[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\nThere are 16.5 million newborns in China annually. However, the incidence of congenital heart disease (CHD) has not been evaluated. In 2004, we launched an active province-wide hospital-based CHD r\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for article in heart_raw2['response']['docs']:\n",
    "    art = re.sub(r'[\\[\\]]','', str(article['abstract']))\n",
    "    heart = heart + art\n",
    "\n",
    "heart[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cancer_clean2 = text_cleaner(cancer)\n",
    "hiv_clean2 = text_cleaner(hiv)\n",
    "heart_clean2 = text_cleaner(heart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_doc2 = nlp(cancer_clean2)\n",
    "hiv_doc2 = nlp(hiv_clean2)\n",
    "heart_doc2 = nlp(heart_clean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting each topic into individual sentences for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1151\n"
     ]
    }
   ],
   "source": [
    "cancer_sents2 = [[sent, 'Cancer'] for sent in cancer_doc2.sents]\n",
    "hiv_sents2 = [[sent, 'HIV'] for sent in hiv_doc2.sents]\n",
    "heart_sents2 = [[sent, 'Heart'] for sent in heart_doc2.sents]\n",
    "\n",
    "sentences2 = pd.DataFrame(cancer_sents2 + hiv_sents2 + heart_sents2)\n",
    "sentences2.head()\n",
    "print(len(sentences2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2120"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerwords2 = bag_of_words2(cancer_doc2)\n",
    "hivwords2 = bag_of_words2(hiv_doc2)\n",
    "heartwords2 = bag_of_words2(heart_doc2)\n",
    "\n",
    "common_words2 = set(cancerwords2 + heartwords2 + hivwords2)\n",
    "len(common_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 100\n",
      "Processing row 200\n"
     ]
    }
   ],
   "source": [
    "word_counts2 = bow_features(sentences2, common_words2)\n",
    "word_counts2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts2['sent_length'] = word_counts2.text_sentence.map(lambda x: len(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = word_counts2['text_source']\n",
    "X2 = np.array(word_counts2.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, \n",
    "                                                    Y2,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression()\n",
    "train = lr2.fit(X_train2, y_train2)\n",
    "print(X_train2.shape, y_train2.shape)\n",
    "print('Training set score:', lr2.score(X_train2, y_train2))\n",
    "print('\\nTest set score:', lr2.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
