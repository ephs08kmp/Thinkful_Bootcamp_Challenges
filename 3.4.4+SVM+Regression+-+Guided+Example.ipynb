{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4.4 SVM Regression Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now it's time for another guided example. This time we're going to look at recipes. Specifically we'll use the epicurious dataset, which has a collection of recipes, key terms and ingredients, and their ratings.\n",
    "\n",
    "What we want to see is if we can use the ingredient and keyword list to predict the rating. For someone writing a cookbook this could be really useful information that could help them choose which recipes to include because they're more likely to be enjoyed and therefore make the book more likely to be successful.\n",
    "\n",
    "First let's load the dataset. It's [available on Kaggle](https://www.kaggle.com/hugodarwood/epirecipes). We'll use the csv file here and as pull out column names and some summary statistics for ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20052.000000\n",
       "mean         3.714467\n",
       "std          1.340829\n",
       "min          0.000000\n",
       "25%          3.750000\n",
       "50%          4.375000\n",
       "75%          4.375000\n",
       "max          5.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We learn a few things from this analysis. From a ratings perspective, there are just over 20,000 recipes with an average rating of 3.71. What is interesting is that the 25th percentile is actually above the mean. This means there is likely some kind of outlier population. This makes sense when we think about reviews: some bad recipes may have very few very low reviews.\n",
    "\n",
    "Let's validate the idea a bit further with a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11395c358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.rating.hist(bins=20)\n",
    "plt.title('Histogram of Recipe Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "So a few things are shown in this histogram. Firstly there are sharp discontinutities. We don't have continuous data. No recipe has a 3.5 rating, for example. Also we see the anticipated increase at 0.\n",
    "\n",
    "Let's try a naive approach again, this time using SVM Regressor. But first, we'll have to do a bit of data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories    4117\n",
       "protein     4162\n",
       "fat         4183\n",
       "sodium      4119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nulls \n",
    "null_count = raw_data.isnull().sum()\n",
    "null_count[null_count>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "What we can see right away is that nutrition information is not available for all goods. Now this would be an interesting data point, but let's focus on ingredients and keywords right now. So we'll actually drop the whole columns for calories, protein, fat, and sodium. We'll come back to nutrition information later.\n",
    "\n",
    "Firstly the overfit is a problem, even though it was poor in the first place. We could go back and clean up our feature set. There might be some gains to be made by getting rid of the noise.\n",
    "\n",
    "We could also see how removing the nulls but including dietary information performs. Though its a slight change to the question we could still possibly get some improvements there.\n",
    "\n",
    "Lastly, we could take our regression problem and turn it into a classifier. With this number of features and a discontinuous outcome, we might have better luck thinking of this as a classification problem. We could make it simpler still by instead of classifying on each possible value, group reviews to some decided high and low values.\n",
    "\n",
    "__And that is your challenge.__\n",
    "\n",
    "Transform this regression problem into a binary classifier and clean up the feature set. You can choose whether or not to include nutritional information, but try to cut your feature set down to the 30 most valuable features.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "\n",
    "## My Code\n",
    "To start, I will create a binary ratings variable where high ratings (greater than 3.5) have a value of 1 and low ratings (3.5 or lower) have a value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#creating binary ratings data and creating the target variable for SVR \n",
    "raw_data['rating_hl'] = raw_data.rating.map(lambda x: 1 if x>3.5 else 0)\n",
    "Y = raw_data.rating_hl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features: Common Ingredients\n",
    "Now, I want to narrow down the ingredients to the top 50 most used ingredients to see if just using common ingredients will allow us to predict if the ratings are high or low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#identifying the top most used ingredients \n",
    "ingred_count = pd.DataFrame(raw_data.drop(['title', 'rating', 'calories', 'protein', 'fat', 'sodium'], 1).sum(), columns=['count'])\n",
    "top_ingred_count = ingred_count.sort_values(by='count', ascending=False).head(30)\n",
    "top_ingred = list(top_ingred_count.index)\n",
    "\n",
    "#setting up columns for top 30 most used ingredients and splitting for train and test\n",
    "X1 = raw_data[top_ingred]\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC Kernels\n",
    "To determine the best kernel to use for this model, I will cross validate with all kernel types to determine which provides the highest accuracy without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'kernel': ('linear', 'poly', 'rbf', 'sigmoid'), 'C': [0.01, 0.1, 1, 10, 100]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#create and fit a ridge regression model, testing each alpha and kernel\n",
    "svc = SVC() \n",
    "grid = GridSearchCV(estimator=svc, param_grid=parameters) \n",
    "grid.fit(X1_train, Y1_train) \n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['linear']}, {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['poly']}, {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['rbf']}, {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['sigmoid']}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "#trying with code from Max\n",
    "parameters = [{'C': [0.01, 0.1, 1, 10, 100], 'kernel':['linear']}, \n",
    "              {'C': [0.01, 0.1, 1, 10, 100], 'kernel':['poly']},\n",
    "               {'C': [0.01, 0.1, 1, 10, 100], 'kernel':['rbf']},\n",
    "               {'C': [0.01, 0.1, 1, 10, 100], 'kernel':['sigmoid']}]\n",
    "\n",
    "#create and fit a ridge regression model, testing each alpha and kernel\n",
    "svc_m = SVC() \n",
    "grid_m = GridSearchCV(estimator=svc_m, param_grid=parameters) \n",
    "grid_m.fit(X1_train, Y1_train) \n",
    "print(grid_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying what the best parameters were from the Grid Search, and identifying the best score from those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.01, 'kernel': 'linear'}\n",
      "Best Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: ', grid_m.best_params_)\n",
    "print('Best Score: ', grid_m.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A R-squared value of 1!?! I assume this is due to overfitting. \n",
    "\n",
    "Let's try the same best parameters from the grid search with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_m.score(X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data set produced the same R-squared value for this model.  I again assume this is due to overfitting.  \n",
    "\n",
    "From my search before, I identified that the poly kernel produced a non-one value of R-squared.  I will run this model again and then cross validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared from Polynomial Kernel:  0.7944677172684353\n",
      "Cross Validation Scores:  [0.79428382 0.79454787 0.79454787 0.79447955 0.79447955]\n"
     ]
    }
   ],
   "source": [
    "#instantiating and fitting model with polynomial kernel\n",
    "svc1_p = SVC(C=0.01, kernel='poly')\n",
    "svc1_p.fit(X1_train, Y1_train)\n",
    "print('R-squared from Polynomial Kernel: ', svc1_p.score(X1_train, Y1_train))\n",
    "print('Cross Validation Scores: ', cross_val_score(svc1_p, X1_train, Y1_train, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating the model through test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7897466586874127"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc1_p.score(X1_test, Y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The consistency of non-one R-squared values in cross validation makes more sense for the data.  This is a pretty accurate model for this data, especially since the test data set has a high R-squared value of 79%. Continue to cross validate with other kernels, but this is a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only kernel that does not overfit the data is the polynomial kernel.  I will try this same cross validation strategy with features that are the ingredients from top-rated recipes.\n",
    "\n",
    "### Features: Top-Rated Ingredients\n",
    "Here I pull all of the ingredients from the top-rated recipes.  The top 30-most used ingredients in these recipes I will use as features for SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the ingredients from top-rated recipes\n",
    "top_rated = raw_data[raw_data['rating'] >= 4]\n",
    "top_rated_count = pd.DataFrame(top_rated.drop(['title', 'rating', 'calories', 'protein', 'fat', 'sodium'], 1).sum())\n",
    "top_rated_count = top_rated_count.sort_values(by=0, ascending=False).head(30)\n",
    "top_rated_ingred = list(top_rated_count.index)\n",
    "\n",
    "#setting up columns for the top-rated ingredients, and splitting into train and test groups\n",
    "X2 = raw_data[top_rated_ingred]\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I will perform a Grid Search CV to identify the best parameters for this top-rated data set, with different kernels and values of C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'kernel': ('linear', 'poly', 'rbf', 'sigmoid'), 'C': [0.1, 1, 10, 100]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10, 100]}\n",
    "\n",
    "#create and fit a ridge regression model, testing each alpha and kernel\n",
    "svc2 = SVC() \n",
    "grid2 = GridSearchCV(estimator=svc2, param_grid=parameters) \n",
    "grid2.fit(X2_train, Y2_train) \n",
    "print(grid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.1, 'kernel': 'linear'}\n",
      "Best Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters: ', grid2.best_params_)\n",
    "print('Best Score: ', grid2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the best kernel is the linear kernel, and the best score is an R-squared value of 1.0.  This model is also overfitting. \n",
    "\n",
    "Just to verify this overfitting, I will run the model against he test data to see how well that predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.score(X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the R-squared for the test data is 1.0.  From my previous work, I will again try the poly kernel to fit the model and cross validate with the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared from Polynomial Kernel:  0.7942017421371101\n",
      "Cross Validation Scores:  [0.79421543 0.79421543 0.79421543 0.79421543 0.79414699]\n"
     ]
    }
   ],
   "source": [
    "#instantiating and fitting polynomial kernel\n",
    "svc2_poly = SVC(C=0.1, kernel='poly')\n",
    "svc2_poly.fit(X2_train, Y2_train)\n",
    "print('R-squared from Polynomial Kernel: ', svc2_poly.score(X2_train, Y2_train))\n",
    "print('Cross Validation Scores: ', cross_val_score(svc2_poly, X2_train, Y2_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905445840813884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc2_poly.score(X2_test, Y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is very slightly more accurate than with the features from the most common ingredients, and cross validation is consistent across folds, but the accuracy in the test data is slightly lower in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Based on the data, the best kernel for this classifier model is the polynomial kernel.  This provided an accuracy of around 79% using 30 ingredients from the top rated recipes.  We will now test the model's accuracy using the test data to determine how well the model predicts values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstabulation:  rating_hl     0     1\n",
      "row_0                \n",
      "1          1050  3963\n",
      "Accuracy of TEST set for SVC Poly Kernel:  0.7905445840813884\n"
     ]
    }
   ],
   "source": [
    "y2_pred_poly = svc2_poly.predict(X2_test)\n",
    "crosstab = pd.crosstab(y2_pred_poly, Y2_test)\n",
    "print('Crosstabulation: ', pd.crosstab(y2_pred_poly, Y2_test))\n",
    "print('Accuracy of TEST set for SVC Poly Kernel: ', svc2_poly.score(X2_test, Y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-rated Ingredients: \n",
      " Index(['rating_hl', 'bon appétit', 'peanut free', 'soy free', 'tree nut free',\n",
      "       'vegetarian', 'kosher', 'gourmet', 'pescatarian', 'quick & easy',\n",
      "       'wheat/gluten-free', 'bake', 'summer', 'dessert', 'fall',\n",
      "       'no sugar added', 'dairy free', 'winter', 'dinner', 'side',\n",
      "       'sugar conscious', 'kidney friendly', 'healthy', 'onion', 'tomato',\n",
      "       'fruit', 'milk/cream', 'sauté', 'vegetable', 'kid-friendly'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Top-rated Ingredients: \\n', X2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 30 ingredients that were present in recipes that were rated over 4 stars produced a support vector machine classification model with the highest accuracy when using the polynomial fit kernel. In using these ingredients, they are not only ingredients, but descriptions of types of recipes.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "When you've finished that, also take a moment to think about bias. Is there anything in this dataset that makes you think it could be biased, perhaps extremely so?\n",
    "\n",
    "There is. Several things in fact, but most glaringly is that we don't actually have a random sample. It could be, and probably is, that the people more likely to choose some kinds of recipes are more likely to give high reviews.\n",
    "\n",
    "After all, people who eat chocolate _might_ just be happier people."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
